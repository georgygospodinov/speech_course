{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f77d818-bc34-4ee0-9694-203fb19fb883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('../asr/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40cb18d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Tuple, List\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sentencepiece\n",
    "import omegaconf\n",
    "import pytorch_lightning as pl\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.models import ConformerLAS, ConformerCTC\n",
    "from src.metrics import WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e5beb0e-684b-4e78-8213-307631a689d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mdiff --git a/conf/conformer_ctc.yaml b/conf/conformer_ctc_wide.yaml\u001b[m\n",
      "\u001b[1mindex ddc568d..702a599 100755\u001b[m\n",
      "\u001b[1m--- a/conf/conformer_ctc.yaml\u001b[m\n",
      "\u001b[1m+++ b/conf/conformer_ctc_wide.yaml\u001b[m\n",
      "\u001b[36m@@ -7,11 +7,11 @@\u001b[m \u001b[mmodel:\u001b[m\n",
      "     dropout: 0.0\u001b[m\n",
      "     feat_in: 64\u001b[m\n",
      "     stride: 4\u001b[m\n",
      "\u001b[31m-    d_model: 256\u001b[m\n",
      "\u001b[31m-    n_layers: 10\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m    d_model: 320\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m    n_layers: 8\u001b[m\n",
      "     n_heads: 8\u001b[m\n",
      "     ff_exp_factor: 2\u001b[m\n",
      "\u001b[31m-    kernel_size: 7\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m    kernel_size: 15\u001b[m\n",
      "     \u001b[m\n",
      " \u001b[m\n",
      "   decoder:\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!git diff --no-index conf/conformer_ctc.yaml conf/conformer_ctc_wide.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28bb692c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(model: pl.LightningModule, ckpt_path: str) -> pl.LightningModule:\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    model.load_state_dict(ckpt)\n",
    "    model.eval()\n",
    "    model.freeze()\n",
    "    return model\n",
    "\n",
    "\n",
    "def compute_wer(refs: Iterable[str], hyps: Iterable[str]) -> float:\n",
    "    wer = WER()\n",
    "    wer.update(refs, hyps)\n",
    "    return wer.compute()[0].item()\n",
    "\n",
    "\n",
    "class GreedyDecoderLAS:\n",
    "    def __init__(self, model: ConformerLAS, max_steps=20):\n",
    "        self.model = model\n",
    "        self.max_steps = max_steps\n",
    "\n",
    "    def __call__(self, encoded: torch.Tensor) -> str:\n",
    "        \n",
    "        tokens = [self.model.decoder.tokenizer.bos_id()]\n",
    "\n",
    "        for _ in range(self.max_steps):\n",
    "            \n",
    "            tokens_batch = torch.tensor(tokens).unsqueeze(0)\n",
    "            att_mask = self.model.make_attention_mask(torch.tensor([tokens_batch.size(-1)]))\n",
    "            \n",
    "            distribution = self.model.decoder(\n",
    "                encoded=encoded, encoded_pad_mask=None,\n",
    "                target=tokens_batch, target_mask=att_mask, target_pad_mask=None\n",
    "            )\n",
    "        \n",
    "            best_next_token = distribution[0, -1].argmax()\n",
    "            \n",
    "            if best_next_token == self.model.decoder.tokenizer.eos_id():\n",
    "                break\n",
    "\n",
    "            tokens.append(best_next_token.item())\n",
    "        \n",
    "        return self.model.decoder.tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7489a3",
   "metadata": {},
   "source": [
    "# Single Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6bd256ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'test_opus/farfield/manifest.jsonl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87d7a33",
   "metadata": {},
   "source": [
    "## LAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91eff477",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = omegaconf.OmegaConf.load(\"./conf/conformer_las.yaml\")\n",
    "conf.val_dataloader.dataset.manifest_name = dataset\n",
    "conf.model.decoder.tokenizer = \"./data/tokenizer/bpe_1024_bos_eos.model\"\n",
    "\n",
    "conformer_las = init_model(\n",
    "    model=ConformerLAS(conf=conf),\n",
    "    ckpt_path=\"./data/conformer_las_2epochs.ckpt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c1fca0c1-c084-4365-b668-b57e32d54581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9841920\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in conformer_las.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1343a50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8f186a2030469dbe5ba2d0ceff2d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "las_decoder = GreedyDecoderLAS(conformer_las)\n",
    "\n",
    "refs, hyps_las = [], []\n",
    "\n",
    "for batch in tqdm(conformer_las.val_dataloader()):\n",
    "\n",
    "    features, features_len, targets, target_len = batch\n",
    "\n",
    "    encoded, encoded_len = conformer_las(features, features_len)\n",
    "    \n",
    "    for i in range(features.shape[0]):\n",
    "\n",
    "        encoder_states = encoded[\n",
    "            [i],\n",
    "            :encoded_len[i],\n",
    "            :\n",
    "        ]\n",
    "\n",
    "        ref_tokens = targets[i, :target_len[i]].tolist()\n",
    "\n",
    "        refs.append(\n",
    "            conformer_las.decoder.tokenizer.decode(ref_tokens)\n",
    "        )\n",
    "        hyps_las.append(\n",
    "            las_decoder(encoder_states)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d05af7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42278361320495605"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_wer(refs, hyps_las)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262680b9",
   "metadata": {},
   "source": [
    "## CTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecca9bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load models, estimate WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3e8ede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_ctc_hyps(model: ConformerCTC) -> Tuple[List[str], List[str]]:\n",
    "    return [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76da07ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9989410\n"
     ]
    }
   ],
   "source": [
    "conf = omegaconf.OmegaConf.load(\"./conf/conformer_ctc.yaml\")\n",
    "conf.val_dataloader.dataset.manifest_name = dataset\n",
    "\n",
    "conformer_ctc = init_model(\n",
    "    model=ConformerCTC(conf=conf),\n",
    "    ckpt_path=\"./data/conformer_7epochs_state_dict.ckpt\"\n",
    ")\n",
    "\n",
    "refs, hyps_ctc = decode_ctc_hyps(conformer_ctc)\n",
    "print(sum(p.numel() for p in conformer_ctc.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64281db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12486114\n"
     ]
    }
   ],
   "source": [
    "conf = omegaconf.OmegaConf.load(\"./conf/conformer_ctc_wide.yaml\")\n",
    "conf.val_dataloader.dataset.manifest_name = dataset\n",
    "\n",
    "conformer_ctc_wide = init_model(\n",
    "    model=ConformerCTC(conf=conf),\n",
    "    ckpt_path=\"./data/conformer_wide_7epochs_state_dict.ckpt\"\n",
    ")\n",
    "\n",
    "refs, hyps_ctc_wide = decode_ctc_hyps(conformer_ctc_wide)\n",
    "print(sum(p.numel() for p in conformer_ctc_wide.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdda104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ba5e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c13f9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'../week07/images/rover_table.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60776f4",
   "metadata": {},
   "source": [
    "# ROVER: Recognizer Output Voting Error Reduction — 5 points\n",
    "\n",
    "* [A post-processing system to yield reduced word error rates: Recognizer Output Voting Error Reduction (ROVER)](https://ieeexplore.ieee.org/document/659110)\n",
    "* [Improved ROVER using Language Model Information](https://www-tlp.limsi.fr/public/asr00_holger.pdf)\n",
    "\n",
    "Alignment + Voting\n",
    "\n",
    "![](./images/rover_table.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167e04f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crowdkit.aggregation.texts import ROVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5480795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: aggregate hypotheses, estimate WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d74139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59efe52d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d69158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd329aa4",
   "metadata": {},
   "source": [
    "# MBR: Minimum Bayes Risk — 5 points\n",
    "\n",
    "\n",
    "* [Minimum Bayes Risk Decoding and System\n",
    "Combination Based on a Recursion for Edit Distance](https://danielpovey.com/files/csl11_consensus.pdf)\n",
    "* [mbr-decoding blog-post](https://suzyahyah.github.io/bayesian%20inference/machine%20translation/2022/02/15/mbr-decoding.html)\n",
    "* [Combination of end-to-end and hybrid models for speech recognition](http://www.interspeech2020.org/uploadfile/pdf/Tue-1-8-4.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e95a625-5bf4-41ce-bee1-e4ea162abf52",
   "metadata": {},
   "source": [
    "![](./images/mbr_scheme.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1fb335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: retrieve minimum-Distance hypothesis, estimate WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3897daf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2c3499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
