{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b90328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from pathlib import Path\n",
    "from typing import Deque, Optional\n",
    "\n",
    "import IPython.display as ipd\n",
    "import ipywidgets as widgets\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyaudio\n",
    "import scipy.signal\n",
    "from ipywidgets import Layout, interact\n",
    "\n",
    "SR = 16000\n",
    "plt.style.use(\"dark_background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d9a7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "/*overwrite hard coded write background by vscode for ipywidges */\n",
    ".cell-output-ipywidget-background {\n",
    "   background-color: transparent !important;\n",
    "}\n",
    "\n",
    "/*set widget foreground text and color of interactive widget to vs dark theme color */\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbc9408",
   "metadata": {},
   "source": [
    "Uncomment if you are using Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39852aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# mkdir -p ./data/{aecs,rirs}\n",
    "# export repo_prefix=https://raw.githubusercontent.com/georgygospodinov/speech_course/main/week02/data\n",
    "# wget -q $repo_prefix/salut_time_query.wav -P data/\n",
    "# wget -q $repo_prefix/aecs/*.wav -P data/aecs\n",
    "# wget -q $repo_prefix/rirs/*.wav -P data/rirs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb24fc5b",
   "metadata": {},
   "source": [
    "# Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7addd95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stream(\n",
    "    pyaudio_manager: pyaudio.PyAudio,\n",
    "    sample_rate: int = 16_000,\n",
    "    frames_per_buffer: int = 160,\n",
    ") -> pyaudio.Stream:\n",
    "    return pyaudio_manager.open(\n",
    "        format=pyaudio.paInt16,\n",
    "        channels=1,\n",
    "        rate=sample_rate,\n",
    "        input=True,\n",
    "        frames_per_buffer=frames_per_buffer,\n",
    "    )\n",
    "\n",
    "\n",
    "def record_audio(stream: pyaudio.Stream, duration_seconds: float = 0.1) -> np.ndarray:\n",
    "    frames_to_read = int(stream._rate * duration_seconds)\n",
    "    byte_frames = stream.read(frames_to_read, exception_on_overflow=False)\n",
    "    audio_frame = np.frombuffer(byte_frames, dtype=np.int16)\n",
    "    float_audio_frame = audio_frame / (1 << 15)\n",
    "    return float_audio_frame\n",
    "\n",
    "\n",
    "def spectral_power(signal: np.ndarray) -> np.ndarray:\n",
    "    spectral_power = np.abs(np.fft.rfft(signal))\n",
    "    return spectral_power\n",
    "\n",
    "\n",
    "def start_recording(chunks: int, sr: int = 16_000) -> deque:\n",
    "    frame_history: Deque = deque(maxlen=chunks)\n",
    "\n",
    "    pa_manager = pyaudio.PyAudio()\n",
    "    stream = create_stream(pa_manager, sample_rate=sr)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            audio_frames = record_audio(stream)\n",
    "            frame_history.append(audio_frames)\n",
    "            data = np.concatenate(list(frame_history))\n",
    "            last_data = frame_history[-1]\n",
    "\n",
    "            plt.figure(figsize=(12, 2))\n",
    "            plt.subplot(121)\n",
    "            plt.axis(\"off\")\n",
    "            plt.grid(False)\n",
    "            plt.ylim(-0.05, 0.05)\n",
    "            plt.plot(data)\n",
    "            plt.subplot(122)\n",
    "\n",
    "            spectrum = spectral_power(last_data)\n",
    "            hz = np.arange(spectrum.size) * (sr / last_data.size)\n",
    "            plt.xlabel(\"Hz\")\n",
    "            plt.xlim(0, 4000)\n",
    "            plt.ylim(0, 4)\n",
    "            plt.plot(hz, spectrum)\n",
    "            plt.show()\n",
    "            ipd.clear_output(wait=True)\n",
    "        except (OSError, KeyboardInterrupt):\n",
    "            pa_manager.terminate()\n",
    "            stream.stop_stream()\n",
    "            stream.close()\n",
    "            break\n",
    "\n",
    "    return frame_history\n",
    "\n",
    "\n",
    "last_audio_chunks = start_recording(chunks=1, sr=SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6fc7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.concatenate(list(last_audio_chunks))\n",
    "\n",
    "plt.figure(figsize=(12, 2))\n",
    "plt.plot(res)\n",
    "plt.show()\n",
    "ipd.Audio(res, rate=SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81968dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_signal, sr = librosa.load(\"./data/salut_time_query.wav\", sr=SR)\n",
    "\n",
    "time_interval = 0.1\n",
    "\n",
    "n_frames = int(sr * time_interval)\n",
    "target_sr = 1_000\n",
    "scale_value = 1 << 12\n",
    "\n",
    "signal_frame = wav_signal[:n_frames]\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.title(\"Analog Signal\")\n",
    "plt.plot(np.arange(n_frames) * time_interval / sr, signal_frame)\n",
    "\n",
    "resampled_signal = librosa.resample(signal_frame, orig_sr=sr, target_sr=target_sr)\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.title(\"Discrete Signal\")\n",
    "plt.stem(np.arange(resampled_signal.size) * time_interval / target_sr, resampled_signal)\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.title(\"Quantized Signal\")\n",
    "plt.plot(\n",
    "    np.arange(n_frames) * time_interval / sr,\n",
    "    (signal_frame * scale_value).astype(\"int\") / scale_value,\n",
    ")\n",
    "plt.subplot(224)\n",
    "plt.title(\"Digital Signal\")\n",
    "plt.stem(\n",
    "    np.arange(resampled_signal.size) * time_interval / target_sr,\n",
    "    (resampled_signal * scale_value).astype(\"int\") / scale_value,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65145e04",
   "metadata": {},
   "source": [
    "# Sampling theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4579c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(\n",
    "    t0=widgets.FloatSlider(\n",
    "        value=1, min=0.1, max=4, layout=Layout(width=\"960px\"), description=r\"$$t_0$$:\"\n",
    "    ),\n",
    "    f0=widgets.FloatSlider(\n",
    "        value=30, min=1, max=1000, layout=Layout(width=\"960px\"), description=r\"$$f_0$$:\"\n",
    "    ),\n",
    "    dt=widgets.FloatSlider(\n",
    "        value=0.4,\n",
    "        min=0.01,\n",
    "        step=0.01,\n",
    "        max=1,\n",
    "        layout=Layout(width=\"960px\"),\n",
    "        description=r\"$$\\Delta t$$:\",\n",
    "    ),\n",
    ")\n",
    "def guassian_pulse_discretization(t0: float, f0: float, dt: float):\n",
    "    def x_time(t):\n",
    "        return np.exp(-((t / t0) ** 2)) * np.cos(f0 * t)\n",
    "\n",
    "    def x_freq(f):\n",
    "        return np.pi**0.5 * t0 * np.exp(-((np.pi * (f - f0) * t0) ** 2))\n",
    "\n",
    "    t = np.linspace(-2, 2, num=4 * 8000)\n",
    "    f = np.linspace(-2.5 * f0, 2.5 * f0, num=4 * 8000)\n",
    "    x_t = x_time(t)\n",
    "    x_f = x_freq(f)\n",
    "\n",
    "    t_steps = np.arange(0, t.max() + dt, step=dt)\n",
    "    t_steps = np.concatenate([-t_steps[:0:-1], t_steps])\n",
    "    x_t_steps = x_time(t_steps)\n",
    "    x_t_reconstructed = sum(\n",
    "        x_t_step * np.sinc((t - t_step) / dt)\n",
    "        for t_step, x_t_step in zip(t_steps, x_t_steps)\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(221)\n",
    "    plt.plot(t, x_t)\n",
    "    plt.title(\"original signal\")\n",
    "    plt.xlabel(\"time\")\n",
    "    plt.subplot(222)\n",
    "    plt.title(\"spectrum\")\n",
    "    plt.plot(f, x_f)\n",
    "    plt.xlabel(\"frequency\")\n",
    "\n",
    "    plt.subplot(223)\n",
    "    plt.title(\"sampled signal points\")\n",
    "    plt.stem(t_steps, x_t_steps)\n",
    "    plt.xlabel(\"time\")\n",
    "    plt.subplot(224)\n",
    "    plt.title(\"reconstruction\")\n",
    "    plt.plot(t, x_t, label=\"original\")\n",
    "    plt.plot(t, x_t_reconstructed, \"--\", label=\"reconstructed\")\n",
    "    plt.scatter(t_steps, x_t_steps, c=\"#feffb3\", label=\"sampled\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"time\")\n",
    "    plt.show()\n",
    "\n",
    "    ipd.display(ipd.Audio(x_t, rate=8000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dbb41e",
   "metadata": {},
   "source": [
    "# Frequency Aliasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2894cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = np.linspace(0, 1, 16)\n",
    "t2 = np.linspace(0, 1, 800)\n",
    "\n",
    "\n",
    "def sin_n(x: np.ndarray, n: int) -> np.ndarray:\n",
    "    return np.sin(2 * np.pi * n * x)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.scatter(t1, sin_n(t1, 1), label=\"discretization points\", color=\"w\", s=50)\n",
    "plt.plot(t2, sin_n(t2, 1), label=r\"$\\sin(\\omega t)$\")\n",
    "plt.plot(t2, sin_n(t2, 16), label=r\"$\\sin(16 \\omega t)$\")\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7e4683",
   "metadata": {},
   "source": [
    "# Spectral Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc767e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(\n",
    "    window_type=widgets.ToggleButtons(\n",
    "        options=[\"uniform\", \"gaussian\"], disabled=False, description=\"window type:\"\n",
    "    ),\n",
    "    window_size=widgets.IntSlider(\n",
    "        value=3,\n",
    "        min=3,\n",
    "        max=51,\n",
    "        step=2,\n",
    "        layout=Layout(width=\"960px\"),\n",
    "        description=\"window_size:\",\n",
    "    ),\n",
    "    power=widgets.IntSlider(\n",
    "        value=10,\n",
    "        min=2,\n",
    "        max=20,\n",
    "        step=2,\n",
    "        layout=Layout(width=\"960px\"),\n",
    "        description=\"power:\",\n",
    "    ),\n",
    ")\n",
    "def smoothing_as_low_frequency_filter(window_type: str, window_size: int, power: int):\n",
    "    t = np.arange(0, 3, step=0.005)\n",
    "    y = np.exp(-(((t - 1) / 0.05) ** power))\n",
    "\n",
    "    if window_type == \"uniform\":\n",
    "        window = np.ones(window_size)\n",
    "    else:\n",
    "        window = scipy.signal.gaussian(M=window_size, std=window_size // 5 + 1)\n",
    "\n",
    "    window /= window.sum()\n",
    "\n",
    "    y_smoothed = np.convolve(\n",
    "        np.pad(y, pad_width=(window.size // 2,), constant_values=(0,)),\n",
    "        window,\n",
    "        mode=\"valid\",\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    plt.subplot(121)\n",
    "    plt.title(\"time domain\")\n",
    "    plt.plot(t, y, label=\"original\")\n",
    "    plt.plot(t, y_smoothed, label=\"smoothed\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.title(\"frequency domain\")\n",
    "    plt.plot(spectral_power(y), label=\"original\")\n",
    "    plt.plot(spectral_power(y_smoothed), label=\"smoothed\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aea7fc",
   "metadata": {},
   "source": [
    "# Impulse Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a669c35",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def display_wav(wav: np.ndarray, sr: int, title: Optional[str] = None) -> None:\n",
    "    ipd.display(ipd.Audio(wav, rate=sr))\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.plot(np.arange(wav.size) / sr, wav)\n",
    "    plt.xlabel(\"seconds\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "music, _ = librosa.load(\"data/aecs/salut_spk.wav\", sr=SR)\n",
    "display_wav(music, SR, title=\"original music\")\n",
    "\n",
    "for rir_path in Path(\"data/rirs\").iterdir():\n",
    "\n",
    "    rir, _ = librosa.load(rir_path, sr=SR)\n",
    "\n",
    "    if rir.size > music.size:\n",
    "        music_padded = np.pad(\n",
    "            music, pad_width=(0, rir.size - music.size), constant_values=(0,)\n",
    "        )\n",
    "        rir_padded = rir[:]\n",
    "    else:\n",
    "        music_padded = music[:]\n",
    "        rir_padded = np.pad(\n",
    "            rir, pad_width=(0, music.size - rir.size), constant_values=(0,)\n",
    "        )\n",
    "\n",
    "    music_f = np.fft.rfft(music_padded)\n",
    "    rir_f = np.fft.rfft(rir_padded)\n",
    "\n",
    "    room_music = np.fft.irfft(music_f * rir_f).real\n",
    "    ipd.display(ipd.Audio(rir_f, rate=SR))\n",
    "    ipd.display(ipd.Audio(room_music, rate=SR))\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(121)\n",
    "    plt.title(\"Room Impulse Response\")\n",
    "    plt.plot(np.arange(rir.size) / SR, rir)\n",
    "    plt.xlabel(\"seconds\")\n",
    "    plt.subplot(122)\n",
    "    plt.title(f\"{rir_path.stem} music\")\n",
    "    plt.plot(np.arange(room_music.size) / SR, room_music)\n",
    "    plt.xlabel(\"seconds\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d16594d",
   "metadata": {},
   "source": [
    "# Acoustic Echo Cancellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca36814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lms(\n",
    "    mic_signal: np.ndarray,\n",
    "    spk_signal: np.ndarray,\n",
    "    window_size: int = 2500,\n",
    "    mu: float = 0.02,\n",
    ") -> np.ndarray:\n",
    "\n",
    "    x = np.pad(spk_signal, pad_width=(window_size - 1, 0), constant_values=(0,))\n",
    "    y = mic_signal[:]\n",
    "    w = np.zeros(window_size)\n",
    "    e = np.zeros(x.size - window_size + 1)\n",
    "\n",
    "    for i in range(x.size - window_size):\n",
    "        x_i = x[i : i + window_size]\n",
    "        e[i] = y[i] - np.dot(x_i, w)\n",
    "        w += mu * e[i] * x_i\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d2346a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parent_dir = Path(\"./data/aecs\")\n",
    "signal_names = (\"salut\", \"doubletalk\")\n",
    "\n",
    "for name in signal_names:\n",
    "    spk_signal, _ = librosa.load(parent_dir / f\"{name}_spk.wav\", sr=SR)\n",
    "    mic_signal, _ = librosa.load(parent_dir / f\"{name}_mic.wav\", sr=SR)\n",
    "\n",
    "    display_wav(spk_signal, SR, title=\"spk signal\")\n",
    "    display_wav(mic_signal, SR, title=\"mic signal\")\n",
    "\n",
    "    lms_result = lms(mic_signal, spk_signal)\n",
    "\n",
    "    ipd.display(ipd.Audio(lms_result, rate=SR))\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(mic_signal, label=\"mic signal\")\n",
    "    plt.plot(lms_result, label=\"enhanced signal\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547af1d9",
   "metadata": {},
   "source": [
    "# Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a25ec4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 3000\n",
    "\n",
    "c = 261\n",
    "d = 294\n",
    "e = 329\n",
    "f = 349\n",
    "g = 391\n",
    "gS = 415\n",
    "a = 440\n",
    "aS = 455\n",
    "b = 466\n",
    "cH = 523\n",
    "cSH = 554\n",
    "dH = 587\n",
    "dSH = 622\n",
    "eH = 659\n",
    "fH = 698\n",
    "fSH = 740\n",
    "gH = 784\n",
    "gSH = 830\n",
    "aH = 880\n",
    "\n",
    "\n",
    "def beep(frequency: int, duration: float, sr: int = 3000) -> np.ndarray:\n",
    "    t = np.linspace(0, duration, int(duration * sr))\n",
    "    return np.sin(2 * np.pi * frequency * t)\n",
    "\n",
    "\n",
    "def delay(duration: float, sr: int = 3000) -> np.ndarray:\n",
    "    t = np.linspace(0, duration, int(duration * sr))\n",
    "    return np.zeros_like(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0183008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "composition = np.hstack(\n",
    "    (\n",
    "        beep(a, 0.500, SR),\n",
    "        beep(a, 0.500, SR),\n",
    "        beep(a, 0.500, SR),\n",
    "        beep(f, 0.350, SR),\n",
    "        beep(cH, 0.150, SR),\n",
    "        beep(a, 0.500, SR),\n",
    "        beep(f, 0.350, SR),\n",
    "        beep(cH, 0.150, SR),\n",
    "        beep(a, 0.650, SR),\n",
    "        delay(0.500, SR),\n",
    "        beep(eH, 0.500, SR),\n",
    "        beep(eH, 0.500, SR),\n",
    "        beep(eH, 0.500, SR),\n",
    "        beep(fH, 0.350, SR),\n",
    "        beep(cH, 0.150, SR),\n",
    "        beep(gS, 0.500, SR),\n",
    "        beep(f, 0.350, SR),\n",
    "        beep(cH, 0.150, SR),\n",
    "        beep(a, 0.650, SR),\n",
    "        beep(aH, 0.500, SR),\n",
    "        beep(a, 0.300, SR),\n",
    "        beep(a, 0.150, SR),\n",
    "        beep(aH, 0.500, SR),\n",
    "        beep(gSH, 0.325, SR),\n",
    "        beep(gH, 0.175, SR),\n",
    "        beep(fSH, 0.125, SR),\n",
    "        beep(fH, 0.125, SR),\n",
    "        beep(fSH, 0.250, SR),\n",
    "        delay(0.325, SR),\n",
    "        beep(aS, 0.250, SR),\n",
    "        beep(dSH, 0.500, SR),\n",
    "        beep(dH, 0.325, SR),\n",
    "        beep(cSH, 0.175, SR),\n",
    "        beep(cH, 0.125, SR),\n",
    "        beep(b, 0.125, SR),\n",
    "        beep(cH, 0.250, SR),\n",
    "        delay(0.350, SR),\n",
    "        beep(f, 0.250, SR),\n",
    "        beep(gS, 0.500, SR),\n",
    "        beep(f, 0.350, SR),\n",
    "        beep(a, 0.125, SR),\n",
    "        beep(cH, 0.500, SR),\n",
    "        beep(a, 0.375, SR),\n",
    "        beep(cH, 0.125, SR),\n",
    "        beep(eH, 0.650, SR),\n",
    "    )\n",
    ")\n",
    "\n",
    "ipd.Audio(composition, rate=SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd15b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
